%! TEX root = ../main.tex
\documentclass[../main.tex]{subfiles}
\begin{document}

% ============================================================ %
% ============================================================ %
\chapter{Statistics}
% ============================================================ %
% ============================================================ %
\section{Random sample}
A random sample is a collection of $n$ random variables $X_1,\dots, X_n$ that are independent and
identically distributed with $X$.

\section{Bias}
The bias of an estimator $\hat{\theta}$ of a parameter $\theta$ is
\begin{align*}
    Bias(\hat{\theta}) = E[\hat{\theta}] - \theta
\end{align*}
An estimator is said unbiased if $Bias(\hat{\theta}) = 0$ .

\section{Mean}
The mean is $\mu = E[X]$ . \\
The sample mean is $\bar{X} = \frac{1}{n} \sum_{i=1}^{n}{X_i}$ . \\
It is unbiased, i.e. $E[\bar{X}] = \mu$ .
\subsection{Central limit theorem}
Let us have a random sample $X_1,\dots, X_n$ following a mean $\mu$ and a variance $\sigma^2$, then we have
\begin{align*}
    &\bar{X} \underset{n \to +\infty}{\sim} \mathcal{N}(\mu, \frac{\sigma}{\sqrt{n}})
\end{align*}

\section{Variance}
The variance is $Var[X] = E[(X - \bar{X})^2]$. \\
The sample variance is $s^2 = \hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^{n}{(X_i - \bar{X})^2}$ \\
It is unbiased, i.e. $E[\hat{\sigma}^2] = \sigma^2$.

\subsection{Chi-squared relation with sample variance}
Let $s^2$ be the sample variance,
\begin{align*}
    \frac{s^2(n-1)}{\sigma^2} \sim \chi_{n-1}^2
\end{align*}

\section{Confidence interval}
A confidence interval $CI_{1-\alpha}$ with confidence level $1-\alpha$ of a true parameter $\theta$
such that
\begin{align*}
    P(\theta \in CI_{1-\alpha}) = 1 - \alpha
\end{align*}

\section{Hypothesis testing}
Let $T$ be the test statistics and $R$ the rejection region.
A test statistic is a statistic (a quantity derived from the sample) used in statistical hypothesis testing.
A hypothesis test is typically specified in terms of a test statistic, considered as a numerical summary
of a dataset that reduces the data to one value that can be used to perform the hypothesis test

\subsection{Type I error}
The type I error, often noted $\alpha$, also called "false alarm" or significance level is the probability
of rejecting the null hypothesis when the null hypothesis is true.
\begin{align*}
    \alpha = P(T \in R\; |\; H_0\; true)
\end{align*}

\subsection{Type II error}
The type II error, often noted $\beta$ also called "missed alarm" is the probability
of not rejecting the null hypothesis when the null hypothesis is false.
\begin{align*}
    \alpha = P(T \notin R\; |\; H_0\; false)
\end{align*}

\subsection{p-value}
The $p$-value is the probability under the null hypothesis of a having a test statistic $T$ at
least as extreme as the one that we observed $T_0$:
\begin{align*}
    \text{(left-sided)} \quad & \text{p-value} = P(T \leq T_0\; |\; H_0\; true) \\
    \text{(right-sided)}\quad & \text{p-value} = P(T \geq T_0\; |\; H_0\; true) \\
    \text{(two-sided)}  \quad & \text{p-value} = P(|T| \geq |T_0|\; |\; H_0\; true) \\
\end{align*}

\subsection{Non-parametric test}
A non-parametric test is a test where we do not have any underlying assumption regarding the
distribution of the sample.

\section{Estimation}
The observed data is $D = (X_1, \dots, X_n)$ . \\
The posterior is $P(\theta\, | \, D)$ . \\
The prior is $P(\theta)$ . \\
The likelihood is $P(D\; |\; \theta)$ . \\
Using Bayes rule $P(\theta | D) = \frac{P(D|\theta)P(\theta)}{P(D)}$,
so $P(\theta | D) \propto P(D|\theta)P(\theta)$ .

\subsubsection{Maximum likelhood estimation (MLE)}
 The maximum likelihood estimation chooses $\theta$ that maximimizes the probability of observed data:
\begin{align*}
    \hat{\theta}_{MLE} = arg\,\underset{\theta}{max}\; P(D\,|\, \theta)
\end{align*}

\subsubsection{Maximum a posteriori estimation (MAP)}
The MAP estimation chooses $\theta$ that is most probable given observed data $D$ and prior belief
$P(\theta)$. \\

\begin{align*}
    \hat{\theta}_{MAP} & = arg\,\underset{\theta}{max}\; P(\theta | D) \\
                       & = arg\,\underset{\theta}{max}\; P(D | \theta) P(\theta) \\
\end{align*}

\section{Bias-variance in estimation}

\section{Markov chains}

A \textbf{stochastic process} $X = \{X(t): t \in T\}$ is a collection of random variables. $X(t)$ is
called the \textbf{state} of the process at $t$. \\

A discrete time process $X = \{X(t): t \in \mathbb{N}\}$ is called a \textbf{Markov chain}
$\Leftrightarrow$
\begin{align*}
    & P(X_t=a_T | X_{t-1} = a_{t-1}, ..., X_0 = a_0) = P(X_t = a_t | X_{t-1} = a_{t-1}) \\
    & \forall t \in \mathbb{N}^*, \quad \forall a_i \in A \\
\end{align*}
A Markov chain is called \textbf{homogeneous} $\Leftrightarrow$ its transition probabilities are
independent of $t$
\begin{align*}
    P_{i,j} = P(X_t = a_j | X_{t-1} = a_i)
\end{align*}
A Markov chain is called \textbf{finite} $\Leftrightarrow$ its set of values is a finite set.
In such a case, we can determine the transition matrix
\begin{align*}
    P = (P_{i, j}) =
    \begin{bmatrix}
        P_{0,0}  & P_{0,1} & ...\\
        P_{1, 0} & P_{1,1} & ...\\
        ...      & ...     & ...\\
    \end{bmatrix}
\end{align*}

We define the \textbf{m-step transition probability} as
\begin{align*}
    &P^n_{i,j} = P(X_{t+n} = a_j | X_{t} = a_i) \\
    &(P^n_{i, j}) = P^n
\end{align*}

\section{Stationarity}
Let $\{ X_t \}$ be a stochastic process, \\
let $F_X(x_{t_1}, ..., x_{t_n})$ represent the cumulative distribution function \\
$\{ X_t \}$ is said to be \textbf{strictly stationary, strongly stationary or strict-sense stationary if}
\begin{align*}
    &F_X(x_{t_1+\tau}, ..., x_{t_n+\tau}) = F_X(x_{t_1}, ..., x_{t_n}) \\
    &\forall \tau, t_1, ..., t_n \in \mathbb{R}, \forall n \in \mathbb{N}
\end{align*}







\section{PCA, ICA}
\subsection{Principal Component Analysis}
In PCA, the basis functions emerge as the eigenvectors of the covariance matrix over observations of
the input data. So the mapping is linear and shallow.

\subsection{Independent Component Analysis}
Can use Noise Contrastive Estimation
F
\end{document}
