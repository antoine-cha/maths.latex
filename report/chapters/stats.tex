%! TEX root = ../main.tex
\documentclass[../main.tex]{subfiles}
\begin{document}

% ============================================================ %
% ============================================================ %
\chapter{Statistics}
% ============================================================ %
% ============================================================ %
\section{Random sample}
A random sample is a collection of $n$ random variables $X_1,\dots, X_n$ that are independent and
identically distributed with $X$.


\section{Mean}
The mean is $\mu = E[X]$ . \\
The sample mean is $\bar{X} = \frac{1}{n} \sum_{i=1}^{n}{X_i}$ . \\
It is unbiased, i.e. $E[\bar{X}] = \mu$ .
\subsection{Central limit theorem}
Let us have a random sample $X_1,\dots, X_n$ following a mean $\mu$ and a variance $\sigma^2$, then we have
\begin{align*}
    &\bar{X} \underset{n \to +\infty}{\sim} \mathcal{N}(\mu, \frac{\sigma}{\sqrt{n}})
\end{align*}

\subsection{Properties}
\begin{align*}
    \text{Linearity }&E[aX + bY] = aE[X] + b[Y]
\end{align*}

\subsection{Law of total expectaction}
\begin{align*}
    &E[X] = E[E[X|Y]]
\end{align*}

\section{Variance}
The variance is $Var[X] = E[(X - \bar{X})^2]$. \\
The sample variance is $s^2 = \hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^{n}{(X_i - \bar{X})^2}$ \\
It is unbiased, i.e. $E[\hat{\sigma}^2] = \sigma^2$.

\subsection{Properties}
\begin{align*}
    \text{Bilinearity }&Var[aX + bY] = a^2Var[X] + 2abCov[X, Y] + b^2 Var[Y]
\end{align*}

\subsection{Chi-squared relation with sample variance}
Let $s^2$ be the sample variance,
\begin{align*}
    \frac{s^2(n-1)}{\sigma^2} \sim \chi_{n-1}^2
\end{align*}

\section{Bias}
The bias of an estimator $\hat{\theta}$ of a parameter $\theta$ is
\begin{align*}
    Bias(\hat{\theta}) = E[\hat{\theta}] - \theta
\end{align*}
An estimator is said unbiased if $Bias(\hat{\theta}) = 0$ .

\subsection{Bias-Variance trade-off}
We want to learn a function $h$ such that $y = h(x)$.
Let \\
\begin{itemize}
    \item $\bar{y}(x) = E_{y|x}[y]$, there is always some unknown on whether we can perfectly model $y$ from $x$
    \item $D$ be a set of pairs $\{(x_1,y_1),\dots,(x_n,y_n)\}$ sampled from $P(x, y)$
\item $\mathcal{A}$ be a learning algorithm such that $h_D = \mathcal{A}(D)$ and $\bar{h} = E_D[h_D]$
\end{itemize}
The expected mean-squared error of our learning algorithm:

\begin{align*}
    E_{x,y,D}[(y - h_D(x))^2] =
        {\underbrace{E_{x}[(\bar{h}(x) - \bar{y}(x))^2]}_{\mathclap {Bias^2}}} +
        {\underbrace{E_{x,D}[(h_D(x) - \bar{h}(x))^2]}_{\mathclap {Variance}}} +
        {\underbrace{E_{x,y}[(y - \bar{y}(x))^2]}_{\matchclap {Noise}}}
\end{align*}



\subsection{Law of total variance}
Also called variance decomposition formula or conditional variance formulas or law of iterated variances
\begin{align*}
    Var(Y) = E[Var(Y | X)] + Var(E[Y | X])
\end{align*}

\section{Types of convergence}

\section{Law of large numbers (LLNs)}
Laws that specify conditions for which the mean estimator converges to a constant.
\subsection{Strong laws}
\subsubsection{Kolmogorov's strong LLNs}
Let $\{X_n\}$ be an \textbf{IID} sequence of random variables having finite mean $\mu < \infty$, then
\begin{align*}
    E[X_n] \xrightarrow{a. s.} \mu
\end{align*}

\subsubsection{Ergodic theorem}
Let $\{X_n\}$ be a \textbf{stationary} and \textbf{ergodic} sequence of random variables having finite mean $\mu < \infty$, then
\begin{align*}
    E[X_n] \xrightarrow{a. s.} \mu
\end{align*}

\subsection{Weak laws}
\subsubsection{Chebyshev's Weak LLNs - uncorrelated}
Let $\{X_n\}$ be an \textbf{uncorrelated} and \textbf{covariance stationary} sequence of random variables, that is
\begin{align*}
    &\exists\, \mu \in \mathbb{R}: E[X_n] = \mu, \forall n \in \mathbb{N} \\
    &\exists\, \sigma^2 \in \mathbb{R}: Var[X_n] = \sigma^2, \forall n \in \mathbb{N} \\
    & Cov[X_n, X_{n+k}] = 0, \forall n,k \in \mathbb{N}
\end{align*}
then a weak LLNs applies
\begin{align*}
    E[X_n] \xrightarrow{p.} \mu
\end{align*}

\subsubsection{Chebyshev's Weak LLNs - correlated}
Let $\{X_n\}$ be an \textbf{correlated} and \textbf{covariance stationary} sequence of random variables, that is
\begin{align*}
    &\exists\, \mu \in \mathbb{R}: E[X_n] = \mu, \forall n \in \mathbb{N} \\
    &\exists\, \sigma^2 \in \mathbb{R}: Var[X_n] = \sigma^2, \forall n \in \mathbb{N} \\
    & Cov[X_n, X_{n+k}] = \gamma_k, \forall n,k \in \mathbb{N}
\end{align*}
Then, \\
\begin{align*}
    &\text{if covariances tend to be 0 in average, that is }\underset{n \to \infty}{lim} \frac{1}{n} \sum_{i=1}^{n} \gamma_i = 0 \\
    &\text{then a weak LLNs applies } E[X_n] \xrightarrow{p.} \mu
\end{align*}

\subsection{For vectors}
The law(s) apply to all components $\Longleftrightarrow$ the law(s) apply the vector.

\section{Moment generating function}
For $X$ a random variable, if $E[e^{xT}]$ exists for $t \in [-h, h], h > 0$,
then $X$ has a moment generating function:
\begin{align*}
    &\text{Definition: }&M_X(t) = E[e^{tX}] \\
    &\text{Moments generation: }&\frac{d^nM_X(0)}{dt^n} = E[X^n] \\
\end{align*}
\subsection{Properties}
\begin{align*}
    &\text{Equality of distributions: }& F_X = F_Y \Longleftrightarrow M_X = M_Y \\
    &\text{Linear transformation: }& Y = a + bX, \, M_Y(t) = e^{at}M_X(bt) \\
    &\text{Sum of mutually independent variables:}& Z =\sum{X_i}, M_Z(t) = \prod{M_{X_i}(t)}
\end{align*}
\subsection{Multivariate}
Use a vector $t$ and the formula becomes $M_X(t) = E[e^{t^TX}]$. \\
By differentiating $n_1, \dots, n_N$ times we can obtain the cross-moments.

\section{Characteristic function}
For $X$ a random variable, the characteristic function always exists.
\begin{align*}
    &\text{Definition: }&\varphi_X(t) = E[e^{itX}] \\
\end{align*}
\subsection{Deriving moments}
If $E[X^n]$ exists and is finite, then
\begin{align*}
    &\varphi_X(t)\text{is n-times continuously differentiable}\\
    &\text{and }\mu_X(n) = E[X^n] = \frac{1}{i^n}\frac{d^n\varphi_X(0)}{dt^n}  \\
\end{align*}
Knowing whether a moment exists is unusual, so a more useful version is: \\
\\
if $\varphi_X(t)$ is n-times differentiable in 0, then
\begin{itemize}
    \item if $n$ is \textbf{even}, $\forall k \leq n, E[X^n]\text{ exists and } E[X^n] = \frac{1}{i^n}\frac{d^n\varphi_X(0)}{dt^n} $
    \item if $n$ is \textbf{odd}, $\forall k < n, E[X^n]\text{ exists and } E[X^n] = \frac{1}{i^n}\frac{d^n\varphi_X(0)}{dt^n} $
\end{itemize}
\subsection{Properties}
\begin{align*}
    &\text{Equality of distributions: }& F_X = F_Y \Longleftrightarrow \varphi_X = \varphi_Y \\
    &\text{Linear transformation: }& Y = a + bX, \, \varphi_Y(t) = e^{iat}\varphi_X(bt) \\
    &\text{Sum of mutually independent variables:}& Z =\sum{X_i}, \varphi_Z(t) = \prod{\varphi_{X_i}(t)}
\end{align*}


\section{Common distributions}
\subsection{Discrete}
\begin{center}
    \begin{tabular}{|c |c |c |c |c|}
        \hline
        Name & Density & Mean & Variance & Mom gen func \\
        \hline
        Uniform - $U(a, b)$& $\frac{1}{b-a}$ & $\frac{a+b}{2}$ & $\frac{(b-a)^2}{12}$ & $m(t)=\frac{e^{bt} - e^{at}}{t(b-a)}$ \\
        \hline
        Bernoulli - $B(p)$ & $f(0)=1-p, f(1)=p$ & $p$ & $p(1-p)$ & $m(t)=pe^t(1-p)$ \\
        \hline
        Binomial(n, p) & $f(x) = \binom{n}{x} p^x(1-p^{n-x})$ & $np$ & $np(1-p)$ & $m(t) = (pe^t + 1-p)^n$\\
        \hline
    \end{tabular}
\end{center}

\subsection{Continuous}
\begin{center}
    \begin{tabular}{|c |c |c |c |c|}
        \hline
        Name & Density & Mean & Variance & Mom gen func \\
        \hline
        Uniform & \\
        \hline
        Bernoulli & \\
        \hline
        Binomial & \\
        \hline
        Binomial & \\
    \end{tabular}
\end{center}

\section{Confidence interval}
A confidence interval $CI_{1-\alpha}$ with confidence level $1-\alpha$ of a true parameter $\theta$
such that
\begin{align*}
    P(\theta \in CI_{1-\alpha}) = 1 - \alpha
\end{align*}

\section{Hypothesis testing}
Let $T$ be the test statistics and $R$ the rejection region.
A test statistic is a statistic (a quantity derived from the sample) used in statistical hypothesis testing.
A hypothesis test is typically specified in terms of a test statistic, considered as a numerical summary
of a dataset that reduces the data to one value that can be used to perform the hypothesis test

\subsection{Type I error}
The type I error, often noted $\alpha$, also called "false alarm" or significance level is the probability
of rejecting the null hypothesis when the null hypothesis is true.
\begin{align*}
    \alpha = P(T \in R\; |\; H_0\; true)
\end{align*}

\subsection{Type II error}
The type II error, often noted $\beta$ also called "missed alarm" is the probability
of not rejecting the null hypothesis when the null hypothesis is false.
\begin{align*}
    \alpha = P(T \notin R\; |\; H_0\; false)
\end{align*}

\subsection{p-value}
The $p$-value is the probability under the null hypothesis of a having a test statistic $T$ at
least as extreme as the one that we observed $T_0$:
\begin{align*}
    \text{(left-sided)} \quad & \text{p-value} = P(T \leq T_0\; |\; H_0\; true) \\
    \text{(right-sided)}\quad & \text{p-value} = P(T \geq T_0\; |\; H_0\; true) \\
    \text{(two-sided)}  \quad & \text{p-value} = P(|T| \geq |T_0|\; |\; H_0\; true) \\
\end{align*}

\subsection{Non-parametric test}
A non-parametric test is a test where we do not have any underlying assumption regarding the
distribution of the sample.

\section{Estimation}
The observed data is $D = (X_1, \dots, X_n)$ . \\
The posterior is $P(\theta\, | \, D)$ . \\
The prior is $P(\theta)$ . \\
The likelihood is $P(D\; |\; \theta)$ . \\
Using Bayes rule $P(\theta | D) = \frac{P(D|\theta)P(\theta)}{P(D)}$,
so $P(\theta | D) \propto P(D|\theta)P(\theta)$ .

\subsubsection{Maximum likelhood estimation (MLE)}
The maximum likelihood estimation chooses $\theta$ that maximimizes the probability of observed data:
\begin{align*}
    \hat{\theta}_{MLE} = arg\,\underset{\theta}{max}\; P(D\,|\, \theta)
\end{align*}

\subsubsection{Maximum a posteriori estimation (MAP)}
The MAP estimation chooses $\theta$ that is most probable given observed data $D$ and prior belief
$P(\theta)$. \\

\begin{align*}
    \hat{\theta}_{MAP} & = arg\,\underset{\theta}{max}\; P(\theta | D) \\
                       & = arg\,\underset{\theta}{max}\; P(D | \theta) P(\theta) \\
\end{align*}

\section{Bias-variance in estimation}

\section{Markov chains}

A \textbf{stochastic process} $X = \{X(t): t \in T\}$ is a collection of random variables. $X(t)$ is
called the \textbf{state} of the process at $t$. \\

A discrete time process $X = \{X(t): t \in \mathbb{N}\}$ is called a \textbf{Markov chain}
$\Leftrightarrow$
\begin{align*}
    & P(X_t=a_T | X_{t-1} = a_{t-1}, ..., X_0 = a_0) = P(X_t = a_t | X_{t-1} = a_{t-1}) \\
    & \forall t \in \mathbb{N}^*, \quad \forall a_i \in A \\
\end{align*}
A Markov chain is called \textbf{homogeneous} $\Leftrightarrow$ its transition probabilities are
independent of $t$
\begin{align*}
    P_{i,j} = P(X_t = a_j | X_{t-1} = a_i)
\end{align*}
A Markov chain is called \textbf{finite} $\Leftrightarrow$ its set of values is a finite set.
In such a case, we can determine the transition matrix
\begin{align*}
    P = (P_{i, j}) =
    \begin{bmatrix}
        P_{0,0}  & P_{0,1} & ...\\
        P_{1, 0} & P_{1,1} & ...\\
        ...      & ...     & ...\\
    \end{bmatrix}
\end{align*}

We define the \textbf{m-step transition probability} as
\begin{align*}
    &P^n_{i,j} = P(X_{t+n} = a_j | X_{t} = a_i) \\
    &(P^n_{i, j}) = P^n
\end{align*}

\section{Stationarity}
Let $\{ X_t \}$ be a stochastic process, \\
let $F_X(x_{t_1}, ..., x_{t_n})$ represent the cumulative distribution function \\
$\{ X_t \}$ is said to be \textbf{strictly stationary, strongly stationary or strict-sense stationary if}
\begin{align*}
    &F_X(x_{t_1+\tau}, ..., x_{t_n+\tau}) = F_X(x_{t_1}, ..., x_{t_n}) \\
    &\forall \tau, t_1, ..., t_n \in \mathbb{R}, \forall n \in \mathbb{N}
\end{align*}

\section{Karush-Kuhn-Tucher (KKT) conditions}


\section{PCA, ICA}
\subsection{Principal Component Analysis}
In PCA, the basis functions emerge as the eigenvectors of the covariance matrix over observations of
the input data. So the mapping is linear and shallow.

\subsection{Independent Component Analysis}
Can use Noise Contrastive Estimation
F
\end{document}
